---
format:
  revealjs:
    embed-resources: true
    slide-number: false
    progress: false
    code-overflow: wrap
    theme: [default, custom.scss]
---

::: {style="text-align: center"}
##  Balancing Precision and Retention<br>in Experimental Design {.center .smaller}

&nbsp;    

:::: columns

::: {.column width="50%"}
**Gustavo Diaz**  
Northwestern University  
<gustavo.diaz@northwestern.edu>  
[gustavodiaz.org](https://gustavodiaz.org)
:::

::: {.column width="50%"}
**Erin Rossiter**  
University of Notre Dame  
<erossite@nd.edu>  
[erossiter.com](https://erossiter.com/)

:::

::::

&nbsp;

Paper and slides: [gustavodiaz.org/talk](https://gustavodiaz.org/talk.html)

:::



```{r include=FALSE}
library(knitr)

opts_chunk$set(fig.pos = "center", echo = FALSE, 
               message = FALSE, warning = FALSE)
```

```{r setup}
# Packages
library(tidyverse)
library(haven)
library(DeclareDesign)
library(tinytable)


# ggplot global options
theme_set(theme_gray(base_size = 20))
ggdodge = position_dodge(width = 0.5)
```

## Bias-variance tradeoff as darts

![](list/darts.png){fig-align="center"}

## But the game of darts is more complicated

:::: columns
::: {.column width="50%"}
![](list/darts_board.png)
:::

::: {.column width="50%"}
![](list/darts_scoring.png){fig-align="center" width="72%" height="72%"}
:::
::::


## Two types of tradeoffs

::: incremental

1. Improve precision at the expense of unbiasedness

2. Improving precision without sacrificing unbiasedness? 
:::

## Two types of tradeoffs

1. [Improve precision at the expense of unbiasedness]{style="color: gray;"}

2. [**Improving precision without sacrificing unbiasedness?**]{style="color: #4E2A84;"}

. . .

&nbsp;

Cost has to come from somewhere else!

## Improving precision in experiments

. . .

Standard error of **estimated ATE** in conventional experimental design [(Gerber and Green 2012, p. 57)]{style="font-size: 50%; color: gray;"}

. . .

$$
SE(\widehat{ATE}) = \sqrt{\frac{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}{N-1}}
$$

::: aside
$N$: Sample size  
$Y_i(*)$: Potential outcomes under treatment/control (1/0)
:::

## Improving precision in experiments

$$
SE(\widehat{ATE}) = \sqrt{\frac{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}{N-1}}
$$

## Improving precision in experiments

$$
SE(\widehat{ATE}) = \sqrt{\frac{\color{#4E2A84}{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}}{N-1}}
$$

. . .

::: {style="color: #4E2A84;"}
**Variance component**

Decrease $SE(\widehat{ATE})$ with **alternative research designs**


:::

## Improving precision in experiments

$$
SE(\widehat{ATE}) = \sqrt{\frac{\color{#4E2A84}{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}}{N-1}}
$$

::: {style="color: #4E2A84;"}
**Variance component**

Decrease $SE(\widehat{ATE})$ with **alternative research designs**

:::: columns
::: {.column width=30%}
::: {style="font-size: 50%;"}
Block-randomization

Repeated measures

Pre-treatment covariates

Pair-matched design

Online balancing

Sequential blocking

Rerandomization

Matching
:::
:::
::::

:::

## Improving precision in experiments

$$
SE(\widehat{ATE}) = \sqrt{\frac{\color{#4E2A84}{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}}{N-1}}
$$

::: {style="color: #4E2A84;"}
**Variance component**

Decrease $SE(\widehat{ATE})$ with **alternative research designs**

:::: columns
::: {.column width=30%}
::: {style="font-size: 50%;"}
**Block-randomization**

**Repeated measures**

Pre-treatment covariates

Pair-matched design

Online balancing

Sequential blocking

Rerandomization

Matching
:::
:::
::::

:::

## Improving precision in experiments

$$
SE(\widehat{ATE}) = \sqrt{\frac{\color{#4E2A84}{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}}{N-1}}
$$

::: {style="color: #4E2A84;"}
**Variance component**

Decrease $SE(\widehat{ATE})$ with **alternative research designs**

:::: columns
::: {.column width=30%}
::: {style="font-size: 50%;"}
**Block-randomization**

**Repeated measures**

Pre-treatment covariates

Pair-matched design

Online balancing

Sequential blocking

Rerandomization

Matching
:::
:::

::: {.column width=70%}

All require **pre-treatment information**


:::
::::

:::

## Improving precision in experiments

$$
SE(\widehat{ATE}) = \sqrt{\frac{\color{#4E2A84}{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}}{N-1}}
$$

::: {style="color: #4E2A84;"}
**Variance component**

Decrease $SE(\widehat{ATE})$ with **alternative research designs**

:::: columns
::: {.column width=30%}
::: {style="font-size: 50%;"}
**Block-randomization**

**Repeated measures**

Pre-treatment covariates

Pair-matched design

Online balancing

Sequential blocking

Rerandomization

Matching
:::
:::

::: {.column width=70%}

All require **pre-treatment information**

Two categories:

::: incremental
1. Reduce variance in *observed* outcomes

2. Reduce variance in *potential* outcomes
:::

:::
::::

:::



## Improving precision in experiments

$$
SE(\widehat{ATE}) = \sqrt{\frac{\color{#4E2A84}{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}}{\color{#00843D}{N-1}}}
$$

. . .

::: {style="color: #00843D;"}
**Sample size component**
:::

## Improving precision in experiments

$$
SE(\widehat{ATE}) = \sqrt{\frac{\color{#4E2A84}{\text{Var}(Y_i(0)) + \text{Var}(Y_i(1)) + 2\text{Cov}(Y_i(0), Y_i(1))}}{\color{#00843D}{N-1}}}
$$

::: {style="color: #00843D;"}
**Sample size component**

Quadruple to halve $SE(\widehat{ATE})$


:::

. . .

**Focus:** Increasing [**numerator**]{style="color: #4E2A84;"} may come at the cost of decreasing [**denominator**]{style="color: #00843D;"}

. . .

[Precision gains from **alternative designs**]{style="color: #4E2A84;"} may be [offset by **sample loss**]{style="color: #00843D;"}

## Sample loss

<!-- Explicit and implicit with examples -->

. . .

**Explicit**

::: incremental

- More pre-treatment questions $\rightarrow$ more attrition/inattention

- Block-randomization $\rightarrow$ discard units

:::



**Implicit**

::: incremental
- Adding a baseline survey $\rightarrow$ half sample size

- Four more survey questions (2 min.) $\rightarrow$ 72% sample size
:::

. . .

*Concerns about prevent widespread implementation*

## Use of alternative designs to increase precision

```{r}
journals = tribble(
  ~` `, ~N, ~`%`,
  "Pre-post", 10, "5%",
  "Blocking", 16, "7%",
  "Both", 6, "3%",
  "Neither", 184, "85%"
)

journals %>% tt() %>% style_tt(fontsize = 0.9)
```


::: aside
Based on articles published in 2022-23 by APSR, AJPS, JOP, PB, CPS, JEPS
:::

## Use of alternative designs to increase precision

```{r}
journals2 = tribble(
  ~` `, ~N, ~`%`,
  "Pre-post", 10, "5%",
  "Blocking", 16, "7%",
  "Both", 6, "3%",
  "Mention covariates", 169, "78%",
  "Nothing", 15, "7%" 
)

journals2 %>% 
  tt() %>% 
  group_tt(i = list(
    "Neither" = 4
  )) %>% 
  style_tt(
    i = 5:6,
    color = "#00000000"
  ) %>% 
  style_tt(fontsize = 0.9)

```


::: aside
Based on articles published in 2022-23 by APSR, AJPS, JOP, PB, CPS, JEPS
:::

## Use of alternative designs to increase precision

```{r}
journals2 = tribble(
  ~` `, ~N, ~`%`,
  "Pre-post", 10, "5%",
  "Blocking", 16, "7%",
  "Both", 6, "3%",
  "Mention covariates", 169, "78%",
  "Nothing", 15, "7%" 
)

journals2 %>% 
  tt() %>% 
  group_tt(i = list(
    "Neither" = 4
  )) %>% 
  style_tt(fontsize = 0.9)

```


::: aside
Based on articles published in 2022-23 by APSR, AJPS, JOP, PB, CPS, JEPS
:::

## Goal

Show that precision gains *offset* sample loss

. . .

**Paper:**

1. Replication of selected studies

2. Simulation on randomly sampled studies

3. Simulations/code/advice for pre-analysis stage

## Goal

Show that precision gains *offset* sample loss


**Paper:**

1. [**Replication of selected studies**]{style="color: #4E2A84;"}

2. [Simulation on randomly sampled studies]{style="color: gray;"}

3. [Simulations/code/advice for pre-analysis stage]{style="color: gray;"}

## Replication studies

```{r}
reps = tribble(
  ~` `, ~`[Dietrich and Hayes (2023)](https://doi.org/10.1086/7239661)`, 
  ~`[Bayram and Graham (2022)](https://doi.org/10.1086/719414)`,
  ~`[Tappin and Hewitt (2023)](https://doi.org/10.1017/XPS.2021.22)`,
  "Study", "1 (DH)", "2 (BG)", "3 (TH)",
  "Subfield", "AP", "IR", "AP",
  "Topic", "Race and issue-based symbolism", "Support for IO foreign aid", "Party cues and policy opinions",
  "Arms", "8", "5", "2",
  "Obs.", "515", "1000", "775",
  "Waves", "1", "1", "2",
  "Concern", "Hard to reach population", "More precision", "Effect persistence"
)

reps %>% tt() %>% 
  format_tt(markdown = TRUE) %>% 
  style_tt(fontsize = 0.8) %>% 
  style_tt(j = 2:4,
           color = "#00000000")
```

## Replication studies

```{r}
reps %>% tt() %>% 
  format_tt(markdown = TRUE) %>% 
  style_tt(fontsize = 0.8) %>% 
  style_tt(j = 3:4,
           color = "#00000000")
```


## Replication studies

```{r}
reps %>% tt() %>% 
  format_tt(markdown = TRUE) %>% 
  style_tt(fontsize = 0.8) %>% 
  style_tt(j = 4,
           color = "#00000000")
```

## Replication studies

```{r}
reps %>% tt() %>% 
  format_tt(markdown = TRUE) %>% 
  style_tt(fontsize = 0.8)
```

## Experimental conditions {#cond}

```{r}
conditions = tribble(
  ~Condition, ~Outcomes, ~Randomization,
  "Design 1", "Post only", "Complete",
  "Design 2", "Pre-post", "Complete",
  "Design 3", "Pre-post", "Blocking"
)

conditions %>% tt()
```

::: incremental
- Sample size same as original
- Increased length (DH: 43%, BG: 50%, TH: 110%)
:::

. . . 

Evaluate extent of explicit/implicit sample loss

::: aside

See more [here](#imp)

:::

## Explicit sample loss

```{r}
exp_loss = data.frame(
  Study = c(rep("DH", 3), rep("BG", 3), rep("TH", 3)),
  Design = rep(c("Standard", "Pre-post", "Pre-post + blocking"), 3),
  Kept = c(99.05, 99.03, 99.03, 
           99.05, 99.05, 99.03,
           87, 85.8, 79.3)
)

exp_loss$Study = fct_relevel(exp_loss$Study,
                             "DH", "BG", "TH")

exp_loss$Design = fct_relevel(exp_loss$Design,
                              "Standard", "Pre-post",
                              "Pre-post + blocking")
ggplot(exp_loss) +
  aes(x = Study, y = Kept, fill = Design) +
  geom_col(width = 0.5, position = "dodge", alpha = 0) + 
  scale_fill_viridis_d() +
  labs(y = "% Sample kept")
```

## Explicit sample loss

```{r}
ggplot(exp_loss) +
  aes(x = Study, y = Kept, fill = Design) +
  geom_col(width = 0.5, position = "dodge") + 
  scale_fill_viridis_d() +
  labs(y = "% Sample kept")
```



## Implicit sample loss

```{r}
sim_summary = readRDS("precision_retention/implicit_loss.rds")

sim_summary = sim_summary %>% 
  mutate(design = ifelse(design == "Pre-post",
                         "Pre-post",
                         "Block randomization"))

sim_summary$design = fct_rev(sim_summary$design)

ggplot(sim_summary, aes(x = pct_loss,
                                                   y = pct_change,
                                                   color = factor(design),
                                                   shape = factor(design))) +
  facet_wrap(~exp, scales = "fixed", nrow = 1) +
  geom_pointrange(aes(ymin = pct_change_025, ymax = pct_change_975), size = 0.5,
                  position = position_dodge2(width = 0.03), alpha = 0) +
  # Horizontal line at 0
  geom_hline(aes(yintercept = 0),
             linetype = "dashed",
             color = "black") +
  theme_gray() +
  theme(
    panel.border = element_rect(color = "black", fill = NA),
    panel.grid.minor.x = element_blank(),
    text = element_text(size = 12),
    axis.title = element_text(size = 12),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    legend.position = "bottom"
  ) +
  labs(x = "Implicit Sample Loss",
       y = "Percentage Change in Standard Error\nRelative to Standard Design",
       color = "Design") + 
  scale_color_manual(values = c("grey50", "grey20")) +
  scale_shape_manual(values = c(16,17)) + 
  guides(color = guide_legend(title = "Design", override.aes = list(shape = c(16,17)),
                              ncol = 2),
         shape = FALSE) +
  scale_y_continuous(limits = c(-50, 90),
                     breaks = seq(-50, 90, by = 25),
                     labels = paste0(seq(-50, 90, by = 25), "%")) +
  scale_x_continuous(breaks = seq(0, .50, by = .10),
                     labels = paste0(seq(0, 50, by = 10), "%"))

```

## Implicit sample loss

```{r}
p0 = ggplot(sim_summary, aes(x = pct_loss,
                                               y = pct_change,
                                               color = factor(design),
                                               shape = factor(design))) +
  facet_wrap(~exp, scales = "fixed", nrow = 1) +
  geom_pointrange(aes(ymin = pct_change_025, ymax = pct_change_975), size = 0.5,
                  position = position_dodge2(width = 0.03)) +
  # Horizontal line at 0
  geom_hline(aes(yintercept = 0),
             linetype = "dashed",
             color = "black") +
  theme_gray() +
  theme(
    panel.border = element_rect(color = "black", fill = NA),
    panel.grid.minor.x = element_blank(),
    text = element_text(size = 12),
    axis.title = element_text(size = 12),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    legend.position = "bottom"
  ) +
  labs(x = "Implicit Sample Loss",
       y = "Percentage Change in Standard Error\nRelative to Standard Design",
       color = "Design") + 
  scale_color_viridis_d(begin = 0, end = 0.8) +
  scale_shape_manual(values = c(16,17)) + 
  guides(color = guide_legend(title = "Design", override.aes = list(shape = c(16,17)),
                              ncol = 2),
         shape = FALSE) +
  scale_y_continuous(limits = c(-50, 90),
                         breaks = seq(-50, 90, by = 25),
                         labels = paste0(seq(-50, 90, by = 25), "%")) +
  scale_x_continuous(breaks = seq(0, .50, by = .10),
                     labels = paste0(seq(0, 50, by = 10), "%"))

p0

```

## Implicit sample loss

```{r}
# annotations

text = data.frame(
  label = c("Sample too small +\n bad proxy outcome", 
            "Ideal case", 
            "Continuous blocking"),
  pct_loss = c(0.2, 0.2, 0.2),
  pct_change = c(-25, 25, 35),
  exp = c("Dietrich & Hayes",
          "Bayram & Graham",
          "Tappin & Hewitt"),
  design = c("Pre-post", "Pre-post", "Block randomization" )
)

text$exp = fct_relevel(text$exp,
                      "Dietrich & Hayes",
          "Bayram & Graham",
          "Tappin & Hewitt" )
p0 +
  geom_text(
    data = text,
    mapping = aes(x = pct_loss, y = pct_change,
                  label = label),
    size = 5
  )
```


## Also in the paper

::: incremental
- No evidence of sample loss altering treatment effects
- No evidence of alternative designs changing *sample composition*
- Simulated replications point in the same direction
- Ideas to navigate choice at pre-analysis stage
:::

## Summary

- **Puzzle:** Alternative designs rare

- **Argument:** Concerns about explicit/implicit sample loss offsetting precision gains

- **Findings:** Alternative designs withstand sample loss

- **Wrinkle:** Alternative designs require more attention!

- **Takeaway:** Try alternative designs!


::: aside
**Paper and slides:** [gustavodiaz.org/talk](https://gustavodiaz.org/talk.html)
:::

## Implementation details {#imp}

![](precision_retention/rep_details.png)

::: aside
[Back](#cond)
:::

