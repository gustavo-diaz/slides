---
format:
  revealjs:
    embed-resources: true
    slide-number: true
---

::: {style="text-align: center"}
## Improving List Experiments {.center .smaller}

&nbsp;


**Gustavo Diaz**  
McMaster University  
[gustavodiaz.org](https://gustavodiaz.org/)  
<diazg2@mcmaster.ca>

&nbsp;

Slides: [talks.gustavodiaz.org/tec](https://talks.gustavodiaz.org/tec.html)

:::


```{r include=FALSE}
library(knitr)

opts_chunk$set(fig.pos = "center", echo = FALSE, 
               message = FALSE, warning = FALSE)
```

```{r setup}
# Packages
library(tidyverse)
library(DeclareDesign)
library(kableExtra)


# ggplot global options
theme_set(theme_gray(base_size = 20))
```

# Research Agenda

## Bias-variance tradeoff as darts

![](list/darts.png){fig-align="center"}

## But the game of darts is more complicated

::: columns
::: {.column width="50%"}
![](list/darts_board.png)
:::

::: {.column width="50%"}
![](list/darts_scoring.png){fig-align="center" width="72%" height="72%"}
:::
:::


## Two types of tradeoffs

::: incremental

1. **Explicit:** Is a little bias worth the increase in precision?

2. **Implicit:** Improving precision without sacrificing unbiasedness? 
:::

## Two types of tradeoffs {visibility="uncounted"}

1. [**Explicit:** Is a little bias worth the increase in precision?]{style="color: gray;"}

2. [**Implicit:** Improving precision without sacrificing unbiasedness?]{style="color: red;"}

# List Experiments

## Example

![](list/personhood_0.png){.absolute top=60 left=0 height="80%"}

. . .

![](list/personhood_1.png){.absolute top=150 left=200}

::: aside
Source: [NPR](https://www.npr.org/sections/itsallpolitics/2011/11/08/142159280/mississippi-voters-reject-personhood-amendment)
:::

## List experiment

Here is a list of things that some people have done. 

::: aside
Source: [Rosenfeld et al (2016)](https://doi.org/10.1111/ajps.12205)
:::

## List experiment {visibility="uncounted"}

Please listen to them and then tell me HOW MANY of them you have done in the past two years. 

::: aside
Source: [Rosenfeld et al (2016)](https://doi.org/10.1111/ajps.12205)
:::

## List experiment {visibility="uncounted"}

Do not tell me which ones. Just tell me HOW MANY:

::: aside
Source: [Rosenfeld et al (2016)](https://doi.org/10.1111/ajps.12205)
:::

. . .

&nbsp;

### Control group

1. Discussed politics with family or friends
2. Cast a ballot for governor Phil Bryant
3. Paid dues to a union
4. Given money to a Tea Party candidate


## List experiment {visibility="uncounted"}

Do not tell me which ones. Just tell me HOW MANY:

::: aside
Source: [Rosenfeld et al (2016)](https://doi.org/10.1111/ajps.12205)
:::

&nbsp;

### Treatment group

1. Discussed politics with family or friends
2. Cast a ballot for governor Phil Bryant
3. Paid dues to a union
4. Given money to a Tea Party candidate
5. **Voted "YES" on the Personhood Initiative**


## Prevalence rate

$$
\text{Proportion(Voted yes)} =\\ \text{Mean(List with sensitive item)} -\\ \text{Mean(List without sensitive item)}
$$

. . .

- We get a **prevalence rate estimate**

. . .

- But we **do not know** how individual respondents voted!

## Compare with direct question

Did you vote YES or NO on the Personhood Initiative, which appeared on the November 2011 Mississippi General Election Ballot?

. . .


$$
\text{Proportion(Voted yes)} =\\ \text{Mean(Voted yes)}
$$


## Validation

```{r}
# got this through
# https://automeris.io/WebPlotDigitizer/
# And by reverse engineering table 1
# Because replication data was not available
# So this has some human error
validation = data.frame(
  technique = c("Direct question", "List experiment"),
  estimate = c(0.396, 0.487),
  upper = c(0.419, 0.562),
  lower = c(0.376, 0.417)
)

actual_vote = 0.65

ggplot(validation) +
  aes(x = technique, y = estimate) +
  geom_point(size = 4, alpha = 0) + 
  geom_linerange(aes(x = technique, ymin = lower, ymax = upper),
                 linewidth = 1, alpha = 0) +
  ylim(0.2, 0.8) +
  labs(x = "Technique", 
       y = "Estimated proportion of 'No' votes")
```

::: aside
Adapted from [Rosenfeld et al (2016)](https://doi.org/10.1111/ajps.12205)
:::

## Validation {visibility="uncounted"}

```{r}
ggplot(validation) +
  aes(x = technique, y = estimate) +
  geom_hline(yintercept = actual_vote, 
             linetype = "dashed",
             linewidth = 1) +
  geom_point(size = 4, alpha = 0) + 
  geom_linerange(aes(x = technique, ymin = lower, ymax = upper),
                 linewidth = 1, alpha = 0) +
  annotate("text", x = 0.7, y = 0.7, size = 5, 
           label = "Actual vote share") +
  ylim(0.2, 0.8) +
  labs(x = "Technique", 
       y = "Estimated proportion of 'No' votes")
```

::: aside
Adapted from [Rosenfeld et al (2016)](https://doi.org/10.1111/ajps.12205)
:::


## Validation {visibility="uncounted"}

```{r}
ggplot(validation) +
  aes(x = technique, y = estimate) +
  geom_hline(yintercept = actual_vote, 
             linetype = "dashed",
             linewidth = 1) +
  geom_point(size = 4) + 
  geom_linerange(aes(x = technique, ymin = lower, ymax = upper),
                 linewidth = 1, alpha = 0) +
  annotate("text", x = 0.7, y = 0.7, size = 5, 
           label = "Actual vote share") +
  ylim(0.2, 0.8) +
  labs(x = "Technique", 
       y = "Estimated proportion of 'No' votes")
```

::: aside
Adapted from [Rosenfeld et al (2016)](https://doi.org/10.1111/ajps.12205)
:::


## Validation {visibility="uncounted"}

```{r}
ggplot(validation) +
  aes(x = technique, y = estimate) +
  geom_hline(yintercept = actual_vote, 
             linetype = "dashed",
             linewidth = 1) +
  geom_point(size = 4) + 
  geom_linerange(aes(x = technique, ymin = lower, ymax = upper),
                 linewidth = 1) +
  annotate("text", x = 0.7, y = 0.7, size = 5, 
           label = "Actual vote share") +
  ylim(0.2, 0.8) +
  labs(x = "Technique", 
       y = "Estimated proportion of 'No' votes")
```

::: aside
Adapted from [Rosenfeld et al (2016)](https://doi.org/10.1111/ajps.12205)
:::

::: {style="text-align: center"}
## Sensitivity bias reduction not always worth the increased variance {.center background-color="#00b176"}
:::

::: {style="text-align: center"}
## Can we do better? {.center background-color="#00b176"}
:::

# Double list experiments

## Example {.smaller}

**List A**

- Californians for Disability (advocating for people with disabilities)
- California National Organization for Women (advocating for women's equality and empowerment)
- American Family Association (advocating for pro-family values)
- American Red Cross (humanitarian organization)

**List B**

- American Legion (veterans service organization)
- Equality California (gay and lesbian advocacy organization)
- Tea Party Patriots (conservative group supporting lower taxes and limited government)
- Salvation Army (charitable organization)

::: aside
Source: [Alvarez et al (2019)](https://doi.org/10.1017/pan.2018.57)
:::

## Sensitive item

**Organization X (advocating for immigration reduction and measures against undocumented immigration)**

::: incremental
- Randomly appears in list A or B

- **Single list:** Half of the respondents see sensitive item

- **Double list:** Everyone sees it

- Equivalent to two parallel list experiments

:::

## Three prevalence estimators

$$
\hat{\tau}_A = \text{Mean}(A_t) - \text{Mean}(A_c)
$$

. . .

$$
\hat{\tau}_B = \text{Mean}(B_t) - \text{Mean}(B_c)
$$

. . .


$$
\hat{\tau}_{Pooled} = (\hat{\tau}_A + \hat{\tau}_B)/2
$$ 

::: aside
See [Diaz (2023)](https://doi.org/10.1017/XPS.2023.24) and [Miller (1984)](https://www.proquest.com/docview/303296717) for details
:::

## DLE yields more precise estimates

```{r}
# Data prep
load("list/attn_rep.RData")

cali = dle

remove(dle)

# Analysis
a = cali %>% 
  split(.$experiment) %>% 
  map(~difference_in_means(listA ~ trt_A, data = .)) %>% 
  map(tidy) %>% 
  bind_rows(.id = "experiment")

b = cali %>% 
  split(.$experiment) %>% 
  map(~difference_in_means(listB ~ trt_B, data = .)) %>% 
  map(tidy) %>% 
  bind_rows(.id = "experiment")

pool = cali %>% 
  mutate(id = row_number()) %>% 
  pivot_longer(cols = c(listA, listB)) %>% 
  rename(list = name, count = value) %>% 
  mutate(Z = ifelse(trt_A == 1 & list == "listA" | trt_B == 1 & list == "listB",
                    1, 0)) %>% 
  split(.$experiment) %>% 
  map(~ lm_robust(count ~ Z + list, clusters = id, se_type = "stata", data = .)) %>% 
  map(tidy) %>% 
  bind_rows(.id = "experiment") %>% 
  filter(term == "Z")
  
est_df = rbind(a, b, pool)

est_df$term = fct_relevel(est_df$term, "trt_A", "trt_B", "Z")
```

```{r}
ggplot(est_df %>% filter(experiment == "X")) +
  aes(x = term, y = estimate, shape = term) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  geom_point(size = 4, position = position_dodge(width = 0.5), alpha = 0) +
  geom_linerange(aes(x = term, ymin = conf.low, ymax = conf.high), 
                 size = 1, position = position_dodge(width = 0.5), alpha = 0) +
  theme(legend.position = "none") +
  labs(subtitle = "Organization X (immigration reduction)",
       x = "Estimator", 
       y = "Proportion support") +
  scale_x_discrete(labels = c("List A", "List B", "Pooled"))
```

::: aside
Adapted from [Diaz (2023)](https://doi.org/10.1017/XPS.2023.24)
:::

## DLE yields more precise estimates {visibility="uncounted"}

```{r}
ggplot(est_df %>% filter(experiment == "X")) +
  aes(x = term, y = estimate, shape = term) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  geom_point(size = 4, position = position_dodge(width = 0.5)) +
  geom_linerange(aes(x = term, ymin = conf.low, ymax = conf.high), 
                 size = 1, position = position_dodge(width = 0.5)) +
  theme(legend.position = "none") +
  labs(subtitle = "Organization X (immigration reduction)", 
       x = "Estimator", 
       y = "Proportion support") +
  scale_x_discrete(labels = c("List A", "List B", "Pooled"))
```

::: aside
Adapted from [Diaz (2023)](https://doi.org/10.1017/XPS.2023.24)
:::

## But variance reduction is not free

::: incremental
- Baseline lists need to be comparable

- Easiest way is to use *paired items* 

- American Family Association (A) $\approx$ Tea Party Patriots (B)

- **BUT** that makes it easier to spot the *sensitive item*
:::

## Different baseline estimates

```{r}
ggplot(est_df %>% filter(experiment == "Y")) +
  aes(x = term, y = estimate, shape = term) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  geom_point(size = 4, position = position_dodge(width = 0.5), alpha = 0) +
  geom_linerange(aes(x = term, ymin = conf.low, ymax = conf.high), 
                 size = 1, position = position_dodge(width = 0.5), alpha = 0) +
  theme(legend.position = "none") +
  labs(subtitle = "Organization Y (citizen border patrol)", 
       x = "Estimator", 
       y = "Proportion support") +
  scale_x_discrete(labels = c("List A", "List B", "Pooled"))
```

::: aside
Adapted from [Diaz (2023)](https://doi.org/10.1017/XPS.2023.24)
:::


## Different baseline estimates {visibility="uncounted"}

```{r}
ggplot(est_df %>% filter(experiment == "Y")) +
  aes(x = term, y = estimate, shape = term) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  geom_point(size = 4, position = position_dodge(width = 0.5)) +
  geom_linerange(aes(x = term, ymin = conf.low, ymax = conf.high), 
                 size = 1, position = position_dodge(width = 0.5)) +
  theme(legend.position = "none") +
  labs(subtitle = "Organization Y (citizen border patrol)", 
       x = "Estimator", 
       y = "Proportion support") +
  scale_x_discrete(labels = c("List A", "List B", "Pooled"))
```

::: aside
Adapted from [Diaz (2023)](https://doi.org/10.1017/XPS.2023.24)
:::

## DLE variants

. . .

```{r}
designs = data.frame(
  expand.grid(
    Lists = c("Fixed", "Randomized"),
    Sensitive_item = c("Fixed", "Randomized")
  )
)

colnames(designs) = c("List order", "Sensitive item location")

designs %>% 
  kbl(escape = FALSE,
      align = "cc")
```

## DLE variants {visibility="uncounted"}

```{r}
designs = data.frame(
  expand.grid(
    Lists = c("Fixed", "Randomized"),
    Sensitive_item = c("Fixed", "Randomized")
  )
)

colnames(designs) = c("List order", "Sensitive item location")

designs %>% 
  kbl(escape = FALSE,
      align = "cc") %>% 
  row_spec(1, strikeout = TRUE, color = "gray")
```

- **Fixed-fixed** is *not* an admissible design

## DLE variants {visibility="uncounted"}

```{r}
designs = data.frame(
  expand.grid(
    Lists = c("Fixed", "Randomized"),
    Sensitive_item = c("Fixed", "Randomized")
  )
)

colnames(designs) = c("List order", "Sensitive item location")

designs %>% 
  kbl(escape = FALSE,
      align = "cc") %>% 
  row_spec(1, strikeout = TRUE, color = "gray") %>% 
  row_spec(2, bold = TRUE)
```

- **Fixed-fixed** is *not* an admissible design
- **Randomized-fixed** keeps sensitive item in second list

## DLE variants {visibility="uncounted"}

```{r}
designs = data.frame(
  expand.grid(
    Lists = c("Fixed", "Randomized"),
    Sensitive_item = c("Fixed", "Randomized")
  )
)

colnames(designs) = c("List order", "Sensitive item location")

designs %>% 
  kbl(escape = FALSE,
      align = "cc") %>% 
  row_spec(1, strikeout = TRUE, color = "gray") %>% 
  row_spec(2, strikeout = TRUE, color = "gray")
```

- **Fixed-fixed** is *not* an admissible design
- **Randomized-fixed** keeps sensitive item in second list

## DLE variants {visibility="uncounted"}

```{r}
designs = data.frame(
  expand.grid(
    Lists = c("Fixed", "Randomized"),
    Sensitive_item = c("Fixed", "Randomized")
  )
)

colnames(designs) = c("List order", "Sensitive item location")

designs %>% 
  kbl(escape = FALSE,
      align = "cc") %>% 
  row_spec(1, strikeout = TRUE, color = "gray") %>% 
  row_spec(2, strikeout = TRUE, color = "gray") %>% 
  row_spec(3:4, bold = TRUE)
```

- **Fixed-fixed** is *not* an admissible design
- **Randomized-fixed** keeps sensitive item in second list
- **Fixed-randomized** and **randomized-randomized** *shuffle sensitive item order*

## Carryover design effects

::: {.callout-note}
## Design effect[(Blair and Imai 2012)](https://doi.org/10.1093/pan/mpr048)

The inclusion of a sensitive item affects how survey participants respond to the baseline items **within the list**.

:::

. . .

::: {.callout-tip}
## Carryover design

The inclusion of a sensitive item **in one list** affects how participants respond to the baseline items in **the other list**.
:::

## Toy example

```{r}
# Four cases
# Baseline (only once)
# Deflation
# Inflation
# Sensitive item

toy = data.frame(
  pot = c("Baseline", rep(c("Sensitive first", "Sensitive second"), 2)),
  Ya = c(2, 1, 2, 3, 2),
  Yb = c(2, 1, 1, 3, 3),
  zz = c(0, 0, 1, 0, -1)
)

colnames(toy) = c("Observed response",
                  "List 1",
                  "List 2",
                  "Difference")

toy %>% 
  kbl(escape = FALSE,
      align = "lcccc") %>% 
  pack_rows("Deflation", 2, 3, color = "white") %>% 
  pack_rows("Inflation", 4, 5, color = "white") %>%  
  column_spec(1, bold = c(T, F, F, F, F)) %>% 
  row_spec(1:5, color = "white")
```

## Toy example {visibility="uncounted"}

```{r}
toy %>% 
  kbl(escape = FALSE,
      align = "lcccc") %>% 
  pack_rows("Deflation", 2, 3, color = "white") %>% 
  pack_rows("Inflation", 4, 5, color = "white") %>%  
  column_spec(1, bold = c(T, F, F, F, F)) %>% 
  row_spec(2:5, color = "white")
```

## Toy example {visibility="uncounted"}

```{r}
toy %>% 
  kbl(escape = FALSE,
      align = "lcccc") %>% 
  pack_rows("Deflation", 2, 3) %>% 
  pack_rows("Inflation", 4, 5, color = "white") %>%  
  column_spec(1, bold = c(T, F, F, F, F)) %>% 
  row_spec(2:5, color = "white")
```

## Toy example {visibility="uncounted"}

```{r}
toy %>% 
  kbl(escape = FALSE,
      align = "lcccc") %>% 
  pack_rows("Deflation", 2, 3) %>% 
  pack_rows("Inflation", 4, 5, color = "white") %>%  
  column_spec(1, bold = c(T, F, F, F, F)) %>% 
  row_spec(3:5, color = "white")
```

## Toy example {visibility="uncounted"}

```{r}
toy %>% 
  kbl(escape = FALSE,
      align = "lcccc") %>% 
  pack_rows("Deflation", 2, 3) %>% 
  pack_rows("Inflation", 4, 5, color = "white") %>%  
  column_spec(1, bold = c(T, F, F, F, F)) %>% 
  row_spec(4:5, color = "white")
```

## Toy example {visibility="uncounted"}

```{r}
toy %>% 
  kbl(escape = FALSE,
      align = "lcccc") %>% 
  pack_rows("Deflation", 2, 3) %>% 
  pack_rows("Inflation", 4, 5) %>%  
  column_spec(1, bold = c(T, F, F, F, F)) %>% 
  row_spec(4:5, color = "white")
```

## Toy example {visibility="uncounted"}

```{r}
toy %>% 
  kbl(escape = FALSE,
      align = "lcccc") %>% 
  pack_rows("Deflation", 2, 3) %>% 
  pack_rows("Inflation", 4, 5) %>%  
  column_spec(1, bold = c(T, F, F, F, F)) %>% 
  row_spec(5, color = "white")
```

## Toy example {visibility="uncounted"}

```{r}
toy %>% 
  kbl(escape = FALSE,
      align = "lcccc") %>% 
  pack_rows("Deflation", 2, 3) %>% 
  pack_rows("Inflation", 4, 5) %>%  
  column_spec(1, bold = c(T, F, F, F, F))
```

## Why does this happen?

::: incremental
- List experiment question format
- Lists usually appear close to each other
- Positively correlation across lists [(Glynn 2013)](https://doi.org/10.1093/poq/nfs070)
:::

## Statistical tests

::: incremental
- **Goal:** Detect *asymmetric shift* across *treatment schedules*

- Two tests: 

1. **Difference-in-differences** (stacked responses)

2. **Signed-rank test** (paired responses)

:::

## Statistical tests {visibility="uncounted"}

<!-- Keep signed rank for appendix -->

- **Goal:** Detect *asymmetric shift* across *treatment schedules*

- Two tests: 

1. [**Difference-in-differences** (clustered responses)]{style="color: red;"}

2. [**Signed-rank test** (paired responses)]{style="color: gray;"}